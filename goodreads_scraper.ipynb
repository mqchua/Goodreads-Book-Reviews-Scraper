{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(\"/Users/ming/Desktop/goodreads/chromedriver\")\n",
    "driver.get(\"https://www.goodreads.com/\")\n",
    "\n",
    "# Login\n",
    "driver.find_element_by_xpath(\n",
    "    '//*[@id=\"userSignInFormEmail\"]').send_keys('') # enter your email \n",
    "driver.find_element_by_xpath(\n",
    "    '//*[@id=\"user_password\"]').send_keys('') # enter your password\n",
    "driver.find_element_by_xpath(\n",
    "    '//*[@id=\"sign_in\"]/div[3]/input[1]').click()\n",
    "\n",
    "\n",
    "# Initialize variables\n",
    "link = []\n",
    "review = []\n",
    "rating = []\n",
    "\n",
    "\n",
    "# Specify page range (1 to 5)\n",
    "for i in range(1, 6):\n",
    "    string = \"https://www.goodreads.com/list/show/264.Books_That_Everyone_Should_Read_At_Least_Once?page=\" + \\\n",
    "        str(i)\n",
    "    driver.get(string)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    links = soup.findAll('a', {'class': 'bookTitle'}, {'itemprop': 'url'})\n",
    "    # append book links\n",
    "    for i in links:\n",
    "        link.append(i['href'])\n",
    "\n",
    "\n",
    "# Remove duplicates\n",
    "link = list(set(link))\n",
    "print(\"No. of books: \", len(link))\n",
    "\n",
    "\n",
    "# Loop through the 300 books to scrape reviews\n",
    "for i in range(len(link)):\n",
    "    print(\"book num:\", i)\n",
    "    print(\"review/rating:\", len(review), len(rating))\n",
    "    driver.get(f\"https://www.goodreads.com{link[i]}\")\n",
    "    soup2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Scrape all 10 pages\n",
    "    for x in range(10):\n",
    "\n",
    "        soup2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        for i in soup2.findAll(class_='friendReviews elementListBrown'):\n",
    "            try:\n",
    "                X = i.find(class_='readable').findAll('span')\n",
    "                B = i.find(class_='staticStars notranslate').find('span')\n",
    "\n",
    "                if (len(X) > 1):\n",
    "                    C = i.find(class_='readable').findAll('span')[1]\n",
    "                else:\n",
    "                    C = i.find(class_='readable').find('span')\n",
    "\n",
    "                if (v is not None for v in [B, C]):\n",
    "                    rating.append(B.text)\n",
    "                    review.append(C.text)\n",
    "            except:\n",
    "                pass\n",
    "        time.sleep(0.5)\n",
    "        try:\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            element = wait.until(EC.element_to_be_clickable(\n",
    "                (By.CLASS_NAME, \"next_page\")))\n",
    "            element.click()\n",
    "            time.sleep(3.0)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "# Print summary\n",
    "print(\"Summary\")\n",
    "print(\"No. of Reviews/Ratings:\", len(review), len(rating))\n",
    "\n",
    "# Convert to csv\n",
    "df = pd.DataFrame()\n",
    "df[\"review\"] = review\n",
    "df[\"rating\"] = rating\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"Final length:\", len(df))\n",
    "df.to_csv('reviews12_14.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
